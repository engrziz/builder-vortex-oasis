import { RequestHandler } from "express";
import OpenAI from "openai";

// Initialize OpenAI client only when needed to avoid build-time errors
let openai: OpenAI | null = null;

const getOpenAIClient = (): OpenAI => {
  if (!openai) {
    openai = new OpenAI({
      apiKey: import.meta.env.VITE_OPENAI_API_KEY,
    });
  }
  return openai;
};

const SYSTEM_PROMPT = `ุฃูุช ูุณุงุนุฏ ุฐูู ูุชุฎุตุต ูู ุชุนููู ุงูุฃุทูุงู ุนู ุงูุฃููุงู ูุงูุฃุณูู ูุงูุงุณุชุซูุงุฑ ุจุงููุบุฉ ุงูุนุฑุจูุฉ. 

ููุงุนุฏ ูููุฉ:
1. ุชุญุฏุซ ุจุงููุบุฉ ุงูุนุฑุจูุฉ ุงููุตุญู ุงูุจุณูุทุฉ ูุงููุงุถุญุฉ ููุฃุทูุงู
2. ุงุณุชุฎุฏู ุฃูุซูุฉ ููุงุณุจุฉ ููุฃุทูุงู ูุชุดุจููุงุช ูู ุญูุงุชูู ุงูููููุฉ
3. ุงุณุชุฎุฏู ุงูุฑููุฒ ุงูุชุนุจูุฑูุฉ ูุฌุนู ุงูุฅุฌุงุจุงุช ููุชุนุฉ ๐๐๐ฐ
4. ุฑูุฒ ููุท ุนูู ููุถูุน ุงููุงู ูุงูุฃุณูู ูุงูุงุณุชุซูุงุฑ ูุงูุงุฏุฎุงุฑ
5. ุฅุฐุง ุณูุฆูุช ุนู ููุถูุน ุฎุงุฑุฌ ูุทุงู ุงูุฃููุงูุ ุฃุนุฏ ุงูุณุคุงู ุจูุทู ุฅูู ุงูููุถูุน ุงููุงูู
6. ุงุฌุนู ุงูุฅุฌุงุจุงุช ูุตูุฑุฉ ููููููุฉ (3-4 ุฌูู ูุญุฏ ุฃูุตู)
7. ุดุฌุน ุงูุฃุทูุงู ุนูู ุงูุงุฏุฎุงุฑ ูุงูุชูููุฑ ุงูุฅูุฌุงุจู ูุญู ุงููุงู

ูุซุงู ุนูู ุฅุฌุงุจุงุชู:
- ุงูุฃุณูู ูุซู ูุทุน ุงูุฃุญุฌูุฉ ูู ุงูุดุฑูุงุช ุงููุจูุฑุฉ! ๐งฉ
- ุงูุงุฏุฎุงุฑ ูุซู ุฒุฑุงุนุฉ ุงูุจุฐูุฑ ุงูุชู ุชููู ูุน ุงูููุช! ๐ฑ
- ุงููุงู ุฃุฏุงุฉ ูููุฏุฉ ูุชุญููู ุฃุญูุงููุง! โจ

ูู ๏ฟฝ๏ฟฝุฏูุฏุงู ููุดุฌุนุงู ููุชุญูุณุงู ูุชุนููู ุงูุฃุทูุงู!`;

export interface ChatRequest {
  message: string;
  conversationHistory?: Array<{ role: 'user' | 'assistant'; content: string }>;
}

export interface ChatResponse {
  response: string;
  error?: string;
}

export const handleAIChat: RequestHandler = async (req, res) => {
  try {
    const { message, conversationHistory = [] }: ChatRequest = req.body;

    if (!process.env.OPENAI_API_KEY) {
      return res.status(500).json({ 
        error: "ููุชุงุญ OpenAI ุบูุฑ ููุนุฑูู ูู ูุชุบูุฑุงุช ุงูุจูุฆุฉ",
        response: "ุนุฐุฑุงูุ ูุง ูููููู ุงูุฅุฌุงุจุฉ ุงูุขู. ูุฑุฌู ุงููุญุงููุฉ ูุงุญูุงู! ๐"
      });
    }

    if (!message || typeof message !== 'string') {
      return res.status(400).json({ 
        error: "ุงูุฑุณุงูุฉ ูุทููุจุฉ",
        response: "ูุฑุฌู ูุชุงุจุฉ ุณุคุงูู! ๐"
      });
    }

    // Build messages array for OpenAI
    const messages: Array<{ role: 'system' | 'user' | 'assistant'; content: string }> = [
      { role: 'system', content: SYSTEM_PROMPT }
    ];

    // Add conversation history (limit to last 10 messages to avoid token limits)
    const recentHistory = conversationHistory.slice(-10);
    for (const msg of recentHistory) {
      messages.push({
        role: msg.role === 'user' ? 'user' : 'assistant',
        content: msg.content
      });
    }

    // Add current user message
    messages.push({ role: 'user', content: message });

    const openaiClient = getOpenAIClient();
    const completion = await openaiClient.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages,
      max_tokens: 200,
      temperature: 0.7,
      top_p: 1,
      frequency_penalty: 0.5,
      presence_penalty: 0.3,
    });

    const response = completion.choices[0]?.message?.content || 
      'ุนุฐุฑุงูุ ูู ุฃุชููู ูู ููู ุณุคุงูู. ูู ููููู ุฅุนุงุฏุฉ ุตูุงุบุชูุ ๐';

    const chatResponse: ChatResponse = { response };
    res.json(chatResponse);

  } catch (error) {
    console.error('OpenAI API Error:', error);
    
    const fallbackResponse = "ุนุฐุฑุงูุ ุญุฏุซ ุฎุทุฃ ุชููู! ๐ ูู ููููู ุงููุญุงููุฉ ูุฑุฉ ุฃุฎุฑูุ ุฃูุง ููุง ูุฃุนููู ุนู ุงูุฃููุงู ูุงูุฃุณูู! ๐ฐ๐";
    
    res.status(500).json({ 
      error: 'ุฎุทุฃ ูู ุงูุฎุงุฏู',
      response: fallbackResponse
    });
  }
};
